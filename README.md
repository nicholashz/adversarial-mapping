# adversarial-mapping

## Introduction
[Word Translation without Parallel Data](https://arxiv.org/abs/1710.04087)  
[Facebook MUSE Github](https://github.com/facebookresearch/MUSE)
<p>The above paper, published by researchers at Facebook, discusses how a bilingual dictionary can be built in an unsupervised way by aligning monolingual word embedding spaces. This is the basis for unsupervised translation done by Facebook's MUSE, also linked above.</p>
<p>The overall idea is to transform two monolingual language dictionaries into their embedding spaces and use adversarial training to find a mapping between them. We can consider a translation from language A to language B as a transformation of the embedding space A to embedding space B. In order to find this transformation in an unsupervised way, we can train two neural networks in parallel. One neural network is the mapper, or the translator, while the other is the discriminator. The mapper learns a translation function from language A to language B, while the discriminator learns to discriminate whether a given word embedding is a true embedding from language B or a translated embedding produced by the mapper.</p>

## This Project
<p>In this project, I generate a toy dataset to implement a simple version of this unsupervised translation learning via adversarial training. Data is generated by a function in toy_data.py, which produced input data (language A) as 2-dimensional points lying in a triangular region and target data (language B) as 2-dimensional points lying in another triangular region which is a 90-degree rotation of A's region.</p>
<p>Since we are trying to learn a 2D rotation, the MapNet is implemented as just a linear layer with 2 inputs and 2 outputs and no bias. Ideally, this would perfectly learn the rotation used to generate language B from language A. The DiscriminatorNet is a DNN with relu activation and dropout between layers to improve robustness.</p>
<p>The two nets are trained together, with the mapper learning to translate language A to language B by trying to "fool" the DiscriminatorNet in a way that it is unable to tell if a point is naturally from language B or if it was translated from language A. We can see by the sample output below that after 25 epochs the mapper has learned to translate language A (red) to language B (blue) in an unsupervised way via this adversarial training.</p>

![Sample Output](sample_output.png?raw=true "Sample Output after Training")

## Usage
### Setup
```
python3 -m venv env
source env/bin/activate
pip3 install -r requirements.txt
```

### Train
```
./train.py
```

### Track
Open localhost:6006 in a browser after running
```
tensorboard --logdir runs/
```
